{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370fb0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m detector \u001b[38;5;241m=\u001b[39m FaceDetector()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     success, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     29\u001b[0m     imgOut \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     30\u001b[0m     img, bboxs \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mfindFaces(img, draw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "import cv2\n",
    "import cvzone\n",
    "from cvzone.FaceDetectionModule import FaceDetector\n",
    "\n",
    "####################################\n",
    "classID = 0  # 0 is fake and 1 is real\n",
    "outputFolderPath = 'C:/Users/elder/BTP/Dataset/DataCollect'\n",
    "confidence = 0.8\n",
    "save = True\n",
    "blurThreshold = 35  # Larger is more focus\n",
    "\n",
    "debug = False\n",
    "offsetPercentageW = 10\n",
    "offsetPercentageH = 20\n",
    "camWidth, camHeight = 640, 480\n",
    "floatingPoint = 6\n",
    "####################################\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, camWidth)\n",
    "cap.set(4, camHeight)\n",
    "\n",
    "detector = FaceDetector()\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgOut = img.copy()\n",
    "    img, bboxs = detector.findFaces(img, draw=False)\n",
    "\n",
    "    listBlur = []  # True False values indicating if the faces are blur or not\n",
    "    listInfo = []  # The normalized values and the class name for the label txt file\n",
    "    if bboxs:\n",
    "        # bboxInfo - \"id\",\"bbox\",\"score\",\"center\"\n",
    "        for bbox in bboxs:\n",
    "            x, y, w, h = bbox[\"bbox\"]\n",
    "            score = bbox[\"score\"][0]\n",
    "            # print(x, y, w, h)\n",
    "\n",
    "            # ------  Check the score --------\n",
    "            if score > confidence:\n",
    "\n",
    "                # ------  Adding an offset to the face Detected --------\n",
    "                offsetW = (offsetPercentageW / 100) * w\n",
    "                x = int(x - offsetW)\n",
    "                w = int(w + offsetW * 2)\n",
    "                offsetH = (offsetPercentageH / 100) * h\n",
    "                y = int(y - offsetH * 3)\n",
    "                h = int(h + offsetH * 3.5)\n",
    "\n",
    "                # ------  To avoid values below 0 --------\n",
    "                if x < 0: x = 0\n",
    "                if y < 0: y = 0\n",
    "                if w < 0: w = 0\n",
    "                if h < 0: h = 0\n",
    "\n",
    "                # ------  Find Blurriness --------\n",
    "                imgFace = img[y:y + h, x:x + w]\n",
    "                cv2.imshow(\"Face\", imgFace)\n",
    "                blurValue = int(cv2.Laplacian(imgFace, cv2.CV_64F).var())\n",
    "                if blurValue > blurThreshold:\n",
    "                    listBlur.append(True)\n",
    "                else:\n",
    "                    listBlur.append(False)\n",
    "\n",
    "                # ------  Normalize Values  --------\n",
    "                ih, iw, _ = img.shape\n",
    "                xc, yc = x + w / 2, y + h / 2\n",
    "\n",
    "                xcn, ycn = round(xc / iw, floatingPoint), round(yc / ih, floatingPoint)\n",
    "                wn, hn = round(w / iw, floatingPoint), round(h / ih, floatingPoint)\n",
    "                # print(xcn, ycn, wn, hn)\n",
    "\n",
    "                # ------  To avoid values above 1 --------\n",
    "                if xcn > 1: xcn = 1\n",
    "                if ycn > 1: ycn = 1\n",
    "                if wn > 1: wn = 1\n",
    "                if hn > 1: hn = 1\n",
    "\n",
    "                listInfo.append(f\"{classID} {xcn} {ycn} {wn} {hn}\\n\")\n",
    "\n",
    "                # ------  Drawing --------\n",
    "                cv2.rectangle(imgOut, (x, y, w, h), (255, 0, 0), 3)\n",
    "                cvzone.putTextRect(imgOut, f'Score: {int(score * 100)}% Blur: {blurValue}', (x, y - 0),\n",
    "                                   scale=2, thickness=3)\n",
    "                if debug:\n",
    "                    cv2.rectangle(img, (x, y, w, h), (255, 0, 0), 3)\n",
    "                    cvzone.putTextRect(img, f'Score: {int(score * 100)}% Blur: {blurValue}', (x, y - 0),\n",
    "                                       scale=2, thickness=3)\n",
    "\n",
    "        # ------  To Save --------\n",
    "        if save:\n",
    "            if all(listBlur) and listBlur != []:\n",
    "                # ------  Save Image  --------\n",
    "                timeNow = time()\n",
    "                timeNow = str(timeNow).split('.')\n",
    "                timeNow = timeNow[0] + timeNow[1]\n",
    "                cv2.imwrite(f\"{outputFolderPath}/{timeNow}.jpg\", img)\n",
    "                # ------  Save Label Text File  --------\n",
    "                for info in listInfo:\n",
    "                    f = open(f\"{outputFolderPath}/{timeNow}.txt\", 'a')\n",
    "                    f.write(info)\n",
    "                    f.close()\n",
    "\n",
    "    cv2.imshow(\"Image\", imgOut)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8f1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
